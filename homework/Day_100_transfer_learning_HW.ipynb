{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Copy of Day_100_transfer_learning_HW.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UupNmtKiGDYs",
        "colab_type": "text"
      },
      "source": [
        "## 作業\n",
        "礙於不是所有同學都有 GPU ，這邊的範例使用的是簡化版本的 ResNet，確保所有同學都能夠順利訓練!\n",
        "\n",
        "\n",
        "最後一天的作業請閱讀這篇非常詳盡的[文章](https://blog.gtwang.org/programming/keras-resnet-50-pre-trained-model-build-dogs-cats-image-classification-system/)，基本上已經涵蓋了所有訓練　CNN 常用的技巧，請使用所有學過的訓練技巧，盡可能地提高 Cifar-10 的 test data 準確率，截圖你最佳的結果並上傳來完成最後一次的作業吧!\n",
        "\n",
        "另外這些技巧在 Kaggle 上也會被許多人使用，更有人會開發一些新的技巧，例如使把預訓練在 ImageNet 上的模型當成 feature extractor 後，再拿擷取出的特徵重新訓練新的模型，這些技巧再進階的課程我們會在提到，有興趣的同學也可以[參考](https://www.kaggle.com/insaff/img-feature-extraction-with-pretrained-resnet)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpNpEMPuGDYt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "afcca337-0058-420c-b09c-7c555afb0e2b"
      },
      "source": [
        "import keras\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from keras.layers import AveragePooling2D, Input, Flatten, Dropout, Dense\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.datasets import cifar10\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.resnet_v2 import ResNet50V2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "#gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "#tf.config.experimental.set_memory_growth(gpu_devices[0], True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN6zaYv9WfZO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "988a61b0-cb95-47e5-bba7-da945395ca60"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-lovTSdGDYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training parameters\n",
        "\n",
        "# 資料路徑\n",
        "DATASET_PATH  = 'data'\n",
        "\n",
        "# 影像大小\n",
        "IMAGE_SIZE = (224, 224)\n",
        "\n",
        "# 影像類別數\n",
        "NUM_CLASSES = 10\n",
        "\n",
        "# 若 GPU 記憶體不足，可調降 batch size 或凍結更多層網路\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# Epoch 數\n",
        "NUM_EPOCHS = 50\n",
        "\n",
        "data_augmentation = True\n",
        "\n",
        "# Subtracting pixel mean improves accuracy\n",
        "subtract_pixel_mean = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRCCqpsIGDYz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f44211bd-94ab-4408-a601-3c20411f8f16"
      },
      "source": [
        "# Load the CIFAR10 data.\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GDz0DjYGDY1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "81160634-1926-4faf-8720-f5c95fd4ea2e"
      },
      "source": [
        "# Input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# Normalize data.\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# If subtract pixel mean is enabled\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = keras.utils.to_categorical(y_test, NUM_CLASSES)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "y_train shape: (50000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAXnRFdaGDY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 1e-3\n",
        "    if epoch > 40:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 30:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 20:\n",
        "        lr *= 1e-1\n",
        "    elif epoch > 10:\n",
        "        lr *= 3e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdecA2cEhayW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    print(K.eval(self.model.optimizer.lr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mosv921yGDY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare model model saving directory.\n",
        "save_dir = '/content/drive/My Drive/MyPy' #os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = f'cifar10_resnet50-final_{NUM_EPOCHS:03d}.h5'\n",
        "\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_accuracy',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=3,\n",
        "                               min_lr=1e-8)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler, MyCallback()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X6As2unGDY7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3e79a4fb-f5b6-47dd-c16c-a767463d650e"
      },
      "source": [
        "# 以訓練好的 ResNet50 為基礎來建立模型，\n",
        "# 捨棄 ResNet50 頂層的 fully connected layers\n",
        "net = ResNet50(include_top=True, \n",
        "               weights='imagenet', \n",
        "               input_tensor=None,\n",
        "               input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
        "\n",
        "# remove classification layer\n",
        "net.layers.pop()\n",
        "net = Model(inputs=net.input, outputs=net.layers[-1].output)\n",
        "\n",
        "# 設定凍結與要進行訓練的網路層\n",
        "for layer in net.layers[:-5]:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = net.output\n",
        "#x = Flatten()(x)\n",
        "\n",
        "# 增加 DropOut layer\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "# 增加 Dense layer，以 softmax 產生個類別的機率值\n",
        "output_layer = Dense(NUM_CLASSES, activation='softmax', kernel_initializer='he_normal', name=\"classifier\")(x)\n",
        "\n",
        "net_final = Model(inputs=net.input, outputs=output_layer)\n",
        "\n",
        "# 使用 Adam optimizer，以較低的 learning rate 進行 fine-tuning\n",
        "net_final.compile(optimizer=RMSprop(learning_rate=lr_schedule(0)),\n",
        "                  loss='categorical_crossentropy', \n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# 輸出整個網路結構\n",
        "print(net_final.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102858752/102853048 [==============================] - 4s 0us/step\n",
            "Learning rate:  0.001\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 2048)         0           activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 2048)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 512)          1049088     dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "classifier (Dense)              (None, 10)           5130        dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 24,641,930\n",
            "Trainable params: 2,108,938\n",
            "Non-trainable params: 22,532,992\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWxNg-MEGDZA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "52b598fe-80fb-4944-b8d2-3cd221c8443c"
      },
      "source": [
        "# Run training, with or without data augmentation.\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    net_final.fit(x_train, y_train,\n",
        "              batch_size=BATCH_SIZE,\n",
        "              epochs=NUM_EPOCHS,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    # 透過 data augmentation 產生訓練與驗證用的影像資料\n",
        "    train_datagen = ImageDataGenerator(rotation_range=20,\n",
        "                                       width_shift_range=0.1,\n",
        "                                       height_shift_range=0.1,\n",
        "                                       shear_range=0.1,\n",
        "                                       zoom_range=0.1,\n",
        "                                       channel_shift_range=0,\n",
        "                                       horizontal_flip=True,\n",
        "                                       fill_mode='nearest')\n",
        "    train_batches = train_datagen.flow_from_directory(DATASET_PATH + '/train_org',\n",
        "                                                      target_size=IMAGE_SIZE,\n",
        "                                                      interpolation='bicubic',\n",
        "                                                      class_mode='categorical',\n",
        "                                                      shuffle=True,\n",
        "                                                      batch_size=BATCH_SIZE)\n",
        "\n",
        "    valid_datagen = ImageDataGenerator()\n",
        "    valid_batches = valid_datagen.flow_from_directory(DATASET_PATH + '/valid_org',\n",
        "                                                      target_size=IMAGE_SIZE,\n",
        "                                                      interpolation='bicubic',\n",
        "                                                      class_mode='categorical',\n",
        "                                                      shuffle=False,\n",
        "                                                      batch_size=BATCH_SIZE)\n",
        "\n",
        "    # 輸出各類別的索引值\n",
        "    for cls, idx in train_batches.class_indices.items():\n",
        "        print('Class #{} = {}'.format(idx, cls))\n",
        "\n",
        "\n",
        "    # Compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    train_datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    # 訓練模型\n",
        "    net_final.fit_generator(train_batches,\n",
        "                            steps_per_epoch = train_batches.samples // BATCH_SIZE,\n",
        "                            validation_data = valid_batches,\n",
        "                            validation_steps = valid_batches.samples // BATCH_SIZE,\n",
        "                            epochs = NUM_EPOCHS, \n",
        "                            verbose=1,\n",
        "                            callbacks=callbacks)\n",
        "    \n",
        "#     net_final.fit_generator(datagen.flow(x_train, y_train, batch_size=BATCH_SIZE),\n",
        "#                         validation_data=(x_test, y_test),\n",
        "#                         epochs=NUM_EPOCHS, verbose=1,   \n",
        "#                         callbacks=callbacks)\n",
        "    \n",
        "# Score trained model.\n",
        "scores = net_final.evaluate_generator(valid_batches, valid_batches.samples // BATCH_SIZE, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Found 50000 images belonging to 10 classes.\n",
            "Found 10000 images belonging to 10 classes.\n",
            "Class #0 = [0]\n",
            "Class #1 = [1]\n",
            "Class #2 = [2]\n",
            "Class #3 = [3]\n",
            "Class #4 = [4]\n",
            "Class #5 = [5]\n",
            "Class #6 = [6]\n",
            "Class #7 = [7]\n",
            "Class #8 = [8]\n",
            "Class #9 = [9]\n",
            "Epoch 1/50\n",
            "Learning rate:  0.001\n",
            "390/390 [==============================] - 845s 2s/step - loss: 0.9363 - accuracy: 0.6925 - val_loss: 0.1668 - val_accuracy: 0.6550\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.65505, saving model to /content/drive/My Drive/MyPy/cifar10_resnet50-final_050.h5\n",
            "0.001\n",
            "Epoch 2/50\n",
            "Learning rate:  0.001\n",
            "390/390 [==============================] - 820s 2s/step - loss: 0.6739 - accuracy: 0.7651 - val_loss: 0.2302 - val_accuracy: 0.6617\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.65505 to 0.66167, saving model to /content/drive/My Drive/MyPy/cifar10_resnet50-final_050.h5\n",
            "0.001\n",
            "Epoch 3/50\n",
            "Learning rate:  0.001\n",
            "390/390 [==============================] - 817s 2s/step - loss: 0.6163 - accuracy: 0.7842 - val_loss: 0.1919 - val_accuracy: 0.6466\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.66167\n",
            "0.001\n",
            "Epoch 4/50\n",
            "Learning rate:  0.001\n",
            "390/390 [==============================] - 825s 2s/step - loss: 0.5823 - accuracy: 0.7996 - val_loss: 0.2144 - val_accuracy: 0.6515\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.66167\n",
            "0.0003162278\n",
            "Epoch 5/50\n",
            "Learning rate:  0.001\n",
            "390/390 [==============================] - 824s 2s/step - loss: 0.5583 - accuracy: 0.8058 - val_loss: 0.3966 - val_accuracy: 0.6826\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.66167 to 0.68264, saving model to /content/drive/My Drive/MyPy/cifar10_resnet50-final_050.h5\n",
            "0.001\n",
            "Epoch 6/50\n",
            "Learning rate:  0.001\n",
            "390/390 [==============================] - 837s 2s/step - loss: 0.5367 - accuracy: 0.8140 - val_loss: 0.6780 - val_accuracy: 0.6693\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.68264\n",
            "0.001\n",
            "Epoch 7/50\n",
            "Learning rate:  0.001\n",
            "390/390 [==============================] - 830s 2s/step - loss: 0.5261 - accuracy: 0.8175 - val_loss: 0.3841 - val_accuracy: 0.6998\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.68264 to 0.69976, saving model to /content/drive/My Drive/MyPy/cifar10_resnet50-final_050.h5\n",
            "0.0003162278\n",
            "Epoch 8/50\n",
            "Learning rate:  0.001\n",
            "390/390 [==============================] - 829s 2s/step - loss: 0.5036 - accuracy: 0.8257 - val_loss: 1.8449 - val_accuracy: 0.6512\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.69976\n",
            "0.001\n",
            "Epoch 9/50\n",
            "Learning rate:  0.001\n",
            "390/390 [==============================] - 829s 2s/step - loss: 0.4992 - accuracy: 0.8285 - val_loss: 2.8777 - val_accuracy: 0.6911\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.69976\n",
            "0.001\n",
            "Epoch 10/50\n",
            "Learning rate:  0.001\n",
            "390/390 [==============================] - 819s 2s/step - loss: 0.4816 - accuracy: 0.8326 - val_loss: 2.3099 - val_accuracy: 0.6866\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.69976\n",
            "0.0003162278\n",
            "Epoch 11/50\n",
            "Learning rate:  0.001\n",
            "390/390 [==============================] - 812s 2s/step - loss: 0.4731 - accuracy: 0.8366 - val_loss: 3.2270 - val_accuracy: 0.6757\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.69976\n",
            "0.001\n",
            "Epoch 12/50\n",
            "Learning rate:  0.0003\n",
            "390/390 [==============================] - 826s 2s/step - loss: 0.4309 - accuracy: 0.8503 - val_loss: 3.0148 - val_accuracy: 0.7089\n",
            "\n",
            "Epoch 00012: val_accuracy improved from 0.69976 to 0.70887, saving model to /content/drive/My Drive/MyPy/cifar10_resnet50-final_050.h5\n",
            "0.0003\n",
            "Epoch 13/50\n",
            "Learning rate:  0.0003\n",
            "390/390 [==============================] - 833s 2s/step - loss: 0.4156 - accuracy: 0.8567 - val_loss: 3.2059 - val_accuracy: 0.7020\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.70887\n",
            "9.486834e-05\n",
            "Epoch 14/50\n",
            "Learning rate:  0.0003\n",
            "390/390 [==============================] - 828s 2s/step - loss: 0.4144 - accuracy: 0.8563 - val_loss: 2.8714 - val_accuracy: 0.7113\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.70887 to 0.71130, saving model to /content/drive/My Drive/MyPy/cifar10_resnet50-final_050.h5\n",
            "0.0003\n",
            "Epoch 15/50\n",
            "Learning rate:  0.0003\n",
            "390/390 [==============================] - 831s 2s/step - loss: 0.4071 - accuracy: 0.8590 - val_loss: 3.6342 - val_accuracy: 0.7005\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.71130\n",
            "0.0003\n",
            "Epoch 16/50\n",
            "Learning rate:  0.0003\n",
            "390/390 [==============================] - 829s 2s/step - loss: 0.4042 - accuracy: 0.8596 - val_loss: 1.7537 - val_accuracy: 0.7033\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.71130\n",
            "9.486834e-05\n",
            "Epoch 17/50\n",
            "Learning rate:  0.0003\n",
            "390/390 [==============================] - 815s 2s/step - loss: 0.3932 - accuracy: 0.8638 - val_loss: 0.9793 - val_accuracy: 0.6936\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.71130\n",
            "0.0003\n",
            "Epoch 18/50\n",
            "Learning rate:  0.0003\n",
            "390/390 [==============================] - 813s 2s/step - loss: 0.3941 - accuracy: 0.8621 - val_loss: 0.5714 - val_accuracy: 0.6905\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.71130\n",
            "0.0003\n",
            "Epoch 19/50\n",
            "Learning rate:  0.0003\n",
            "390/390 [==============================] - 813s 2s/step - loss: 0.3859 - accuracy: 0.8655 - val_loss: 1.0734 - val_accuracy: 0.7101\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.71130\n",
            "9.486834e-05\n",
            "Epoch 20/50\n",
            "Learning rate:  0.0003\n",
            "390/390 [==============================] - 805s 2s/step - loss: 0.3806 - accuracy: 0.8672 - val_loss: 0.5775 - val_accuracy: 0.7177\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.71130 to 0.71769, saving model to /content/drive/My Drive/MyPy/cifar10_resnet50-final_050.h5\n",
            "0.0003\n",
            "Epoch 21/50\n",
            "Learning rate:  0.0003\n",
            "390/390 [==============================] - 815s 2s/step - loss: 0.3762 - accuracy: 0.8697 - val_loss: 0.6794 - val_accuracy: 0.6948\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.71769\n",
            "0.0003\n",
            "Epoch 22/50\n",
            "Learning rate:  0.0001\n",
            "390/390 [==============================] - 815s 2s/step - loss: 0.3683 - accuracy: 0.8726 - val_loss: 0.7400 - val_accuracy: 0.7042\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.71769\n",
            "3.1622774e-05\n",
            "Epoch 23/50\n",
            "Learning rate:  0.0001\n",
            "390/390 [==============================] - 817s 2s/step - loss: 0.3679 - accuracy: 0.8713 - val_loss: 0.6627 - val_accuracy: 0.7014\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.71769\n",
            "1e-04\n",
            "Epoch 24/50\n",
            "Learning rate:  0.0001\n",
            "390/390 [==============================] - 811s 2s/step - loss: 0.3639 - accuracy: 0.8743 - val_loss: 0.6817 - val_accuracy: 0.6964\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.71769\n",
            "1e-04\n",
            "Epoch 25/50\n",
            "Learning rate:  0.0001\n",
            "390/390 [==============================] - 807s 2s/step - loss: 0.3558 - accuracy: 0.8767 - val_loss: 0.5168 - val_accuracy: 0.7010\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.71769\n",
            "3.1622774e-05\n",
            "Epoch 26/50\n",
            "Learning rate:  0.0001\n",
            "390/390 [==============================] - 810s 2s/step - loss: 0.3590 - accuracy: 0.8744 - val_loss: 0.6547 - val_accuracy: 0.7049\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.71769\n",
            "1e-04\n",
            "Epoch 27/50\n",
            "Learning rate:  0.0001\n",
            "390/390 [==============================] - 806s 2s/step - loss: 0.3515 - accuracy: 0.8767 - val_loss: 0.6416 - val_accuracy: 0.7105\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.71769\n",
            "1e-04\n",
            "Epoch 28/50\n",
            "Learning rate:  0.0001\n",
            "390/390 [==============================] - 814s 2s/step - loss: 0.3549 - accuracy: 0.8751 - val_loss: 0.6506 - val_accuracy: 0.6991\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.71769\n",
            "3.1622774e-05\n",
            "Epoch 29/50\n",
            "Learning rate:  0.0001\n",
            "390/390 [==============================] - 820s 2s/step - loss: 0.3541 - accuracy: 0.8754 - val_loss: 0.6737 - val_accuracy: 0.7021\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.71769\n",
            "1e-04\n",
            "Epoch 30/50\n",
            "Learning rate:  0.0001\n",
            "390/390 [==============================] - 821s 2s/step - loss: 0.3473 - accuracy: 0.8774 - val_loss: 0.5608 - val_accuracy: 0.7056\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.71769\n",
            "1e-04\n",
            "Epoch 31/50\n",
            "Learning rate:  0.0001\n",
            "390/390 [==============================] - 802s 2s/step - loss: 0.3443 - accuracy: 0.8785 - val_loss: 0.7937 - val_accuracy: 0.6987\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.71769\n",
            "3.1622774e-05\n",
            "Epoch 32/50\n",
            "Learning rate:  1e-05\n",
            "390/390 [==============================] - 815s 2s/step - loss: 0.3456 - accuracy: 0.8794 - val_loss: 0.9703 - val_accuracy: 0.7029\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.71769\n",
            "1e-05\n",
            "Epoch 33/50\n",
            "Learning rate:  1e-05\n",
            "390/390 [==============================] - 815s 2s/step - loss: 0.3454 - accuracy: 0.8798 - val_loss: 1.4520 - val_accuracy: 0.7027\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.71769\n",
            "1e-05\n",
            "Epoch 34/50\n",
            "Learning rate:  1e-05\n",
            "390/390 [==============================] - 814s 2s/step - loss: 0.3411 - accuracy: 0.8815 - val_loss: 1.1211 - val_accuracy: 0.7033\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.71769\n",
            "3.1622776e-06\n",
            "Epoch 35/50\n",
            "Learning rate:  1e-05\n",
            "390/390 [==============================] - 812s 2s/step - loss: 0.3478 - accuracy: 0.8794 - val_loss: 1.4085 - val_accuracy: 0.7022\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.71769\n",
            "1e-05\n",
            "Epoch 36/50\n",
            "Learning rate:  1e-05\n",
            "390/390 [==============================] - 811s 2s/step - loss: 0.3432 - accuracy: 0.8792 - val_loss: 1.4067 - val_accuracy: 0.7036\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.71769\n",
            "1e-05\n",
            "Epoch 37/50\n",
            "Learning rate:  1e-05\n",
            "390/390 [==============================] - 812s 2s/step - loss: 0.3461 - accuracy: 0.8789 - val_loss: 1.3668 - val_accuracy: 0.7016\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.71769\n",
            "3.1622776e-06\n",
            "Epoch 38/50\n",
            "Learning rate:  1e-05\n",
            "390/390 [==============================] - 811s 2s/step - loss: 0.3434 - accuracy: 0.8790 - val_loss: 1.5304 - val_accuracy: 0.7026\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.71769\n",
            "1e-05\n",
            "Epoch 39/50\n",
            "Learning rate:  1e-05\n",
            "390/390 [==============================] - 805s 2s/step - loss: 0.3387 - accuracy: 0.8812 - val_loss: 1.0559 - val_accuracy: 0.7032\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.71769\n",
            "1e-05\n",
            "Epoch 40/50\n",
            "Learning rate:  1e-05\n",
            "390/390 [==============================] - 803s 2s/step - loss: 0.3420 - accuracy: 0.8795 - val_loss: 1.3345 - val_accuracy: 0.7045\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.71769\n",
            "3.1622776e-06\n",
            "Epoch 41/50\n",
            "Learning rate:  1e-05\n",
            "390/390 [==============================] - 815s 2s/step - loss: 0.3388 - accuracy: 0.8830 - val_loss: 1.7669 - val_accuracy: 0.7042\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.71769\n",
            "1e-05\n",
            "Epoch 42/50\n",
            "Learning rate:  1e-06\n",
            "390/390 [==============================] - 813s 2s/step - loss: 0.3439 - accuracy: 0.8787 - val_loss: 1.3277 - val_accuracy: 0.7053\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.71769\n",
            "1e-06\n",
            "Epoch 43/50\n",
            "Learning rate:  1e-06\n",
            "390/390 [==============================] - 813s 2s/step - loss: 0.3447 - accuracy: 0.8799 - val_loss: 1.6829 - val_accuracy: 0.7046\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.71769\n",
            "3.1622776e-07\n",
            "Epoch 44/50\n",
            "Learning rate:  1e-06\n",
            "390/390 [==============================] - 813s 2s/step - loss: 0.3387 - accuracy: 0.8820 - val_loss: 1.2992 - val_accuracy: 0.7045\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.71769\n",
            "1e-06\n",
            "Epoch 45/50\n",
            "Learning rate:  1e-06\n",
            "  2/390 [..............................] - ETA: 7:14 - loss: 0.3759 - accuracy: 0.8828"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7shxGeEGDZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "0 : airplain (飛機)\n",
        "1 : automobile (汽車)\n",
        "2 : bird (鳥)\n",
        "3 : cat (貓)\n",
        "4 : deer (鹿)\n",
        "5 : dog (狗)\n",
        "6 : frog (青蛙)\n",
        "7 : horse (馬)\n",
        "8 : ship (船)\n",
        "9 : truck (卡車)\n",
        "'''    \n",
        "def array_to_image(X, y, path=\"train\", resize=False, imgsize=(224,224)):\n",
        "    from PIL import Image\n",
        "    import numpy as np\n",
        "    import os\n",
        "\n",
        "    base_path = os.path.join(os.getcwd(), DATASET_PATH)\n",
        "    # 檢查路徑是否存在\n",
        "    if not os.path.exists(base_path):\n",
        "        os.mkdir(base_path)\n",
        "        print(\"creat dir\", base_path)\n",
        "    \n",
        "    path = os.path.join(base_path, path)        \n",
        "    # 檢查路徑是否存在\n",
        "    if not os.path.exists(path):\n",
        "        os.mkdir(path)\n",
        "        print(\"creat dir\", path)\n",
        "    \n",
        "    if len(X) != len(y):\n",
        "        print(\"data Mismatch\")\n",
        "        return\n",
        "\n",
        "    for i in range(0, len(X)):\n",
        "        filepath = os.path.join(path, str(y[i]))\n",
        "        if not os.path.exists(filepath):\n",
        "            os.mkdir(filepath)\n",
        "            print(\"creat dir\", filepath)\n",
        "            \n",
        "        # 將圖片使用 BICUBIC 方式延伸到 224 x 224\n",
        "        img = X[i]\n",
        "        img = Image.fromarray(img)\n",
        "        if resize:\n",
        "            img = img.resize(imgsize, Image.BICUBIC)\n",
        "        filename = os.path.join(filepath, str(i)+\".png\")\n",
        "        img.save(filename)\n",
        "        #print(\"save\", filename)\n",
        "            \n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdpMPG9ZGDZE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "1ba97a0f-d0d1-4cc2-a219-11e81d58adf2"
      },
      "source": [
        "#array_to_image(x_train, y_train, \"train\", True, IMAGE_SIZE)\n",
        "array_to_image(x_train, y_train, \"train_org\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "creat dir /content/data\n",
            "creat dir /content/data/train_org\n",
            "creat dir /content/data/train_org/[6]\n",
            "creat dir /content/data/train_org/[9]\n",
            "creat dir /content/data/train_org/[4]\n",
            "creat dir /content/data/train_org/[1]\n",
            "creat dir /content/data/train_org/[2]\n",
            "creat dir /content/data/train_org/[7]\n",
            "creat dir /content/data/train_org/[8]\n",
            "creat dir /content/data/train_org/[3]\n",
            "creat dir /content/data/train_org/[5]\n",
            "creat dir /content/data/train_org/[0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5F3wzYDGDZG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "dde3cefa-cea2-4bf5-f6c9-8a6c80c73b92"
      },
      "source": [
        "#array_to_image(x_test, y_test, \"valid\", True, IMAGE_SIZE)\n",
        "array_to_image(x_test, y_test, \"valid_org\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "creat dir /content/data/valid_org\n",
            "creat dir /content/data/valid_org/[3]\n",
            "creat dir /content/data/valid_org/[8]\n",
            "creat dir /content/data/valid_org/[0]\n",
            "creat dir /content/data/valid_org/[6]\n",
            "creat dir /content/data/valid_org/[1]\n",
            "creat dir /content/data/valid_org/[9]\n",
            "creat dir /content/data/valid_org/[5]\n",
            "creat dir /content/data/valid_org/[7]\n",
            "creat dir /content/data/valid_org/[4]\n",
            "creat dir /content/data/valid_org/[2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXf8Sw1YMUXE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}