{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UupNmtKiGDYs"
   },
   "source": [
    "## 作業\n",
    "礙於不是所有同學都有 GPU ，這邊的範例使用的是簡化版本的 ResNet，確保所有同學都能夠順利訓練!\n",
    "\n",
    "\n",
    "最後一天的作業請閱讀這篇非常詳盡的[文章](https://blog.gtwang.org/programming/keras-resnet-50-pre-trained-model-build-dogs-cats-image-classification-system/)，基本上已經涵蓋了所有訓練　CNN 常用的技巧，請使用所有學過的訓練技巧，盡可能地提高 Cifar-10 的 test data 準確率，截圖你最佳的結果並上傳來完成最後一次的作業吧!\n",
    "\n",
    "另外這些技巧在 Kaggle 上也會被許多人使用，更有人會開發一些新的技巧，例如使把預訓練在 ImageNet 上的模型當成 feature extractor 後，再拿擷取出的特徵重新訓練新的模型，這些技巧再進階的課程我們會在提到，有興趣的同學也可以[參考](https://www.kaggle.com/insaff/img-feature-extraction-with-pretrained-resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dpNpEMPuGDYt"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten, Dropout, Dense\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet_v2 import ResNet50V2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "#gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_memory_growth(gpu_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l-lovTSdGDYx"
   },
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "\n",
    "# 資料路徑\n",
    "DATASET_PATH  = 'data'\n",
    "\n",
    "# 影像大小\n",
    "IMAGE_SIZE = (224, 224)\n",
    "\n",
    "# 影像類別數\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# 若 GPU 記憶體不足，可調降 batch size 或凍結更多層網路\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Epoch 數\n",
    "NUM_EPOCHS = 40\n",
    "\n",
    "data_augmentation = True\n",
    "\n",
    "# Subtracting pixel mean improves accuracy\n",
    "subtract_pixel_mean = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rRCCqpsIGDYz"
   },
   "outputs": [],
   "source": [
    "# Load the CIFAR10 data.\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "4GDz0DjYGDY1",
    "outputId": "43c60f63-140a-4e19-e0f9-70a3b29e95d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Input image dimensions.\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "# Normalize data.\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# If subtract pixel mean is enabled\n",
    "if subtract_pixel_mean:\n",
    "    x_train_mean = np.mean(x_train, axis=0)\n",
    "    x_train -= x_train_mean\n",
    "    x_test -= x_train_mean\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test = keras.utils.to_categorical(y_test, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cAXnRFdaGDY4"
   },
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "    Learning rate is scheduled to be reduced after 10, 20, 30, 40 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 40:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 30:\n",
    "        lr *= 3e-2\n",
    "    elif epoch > 20:\n",
    "        lr *= 1e-1\n",
    "    elif epoch > 10:\n",
    "        lr *= 3e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7X6As2unGDY7",
    "outputId": "0ae416e4-28c2-42f1-fd59-02c662c94e74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_246[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_248[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_81 (Add)                    (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 56, 56, 256)  0           add_81[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_251[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_82 (Add)                    (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 56, 56, 256)  0           add_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_83 (Add)                    (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 56, 56, 256)  0           add_83[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_256[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_84 (Add)                    (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 28, 28, 512)  0           add_84[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_259[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_85 (Add)                    (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 28, 28, 512)  0           add_85[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_262[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_263[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_86 (Add)                    (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 28, 28, 512)  0           add_86[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_264[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_266[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_87 (Add)                    (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_264[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, 28, 28, 512)  0           add_87[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_267[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_268[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_267[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_88 (Add)                    (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, 14, 14, 1024) 0           add_88[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_270[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_271[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_89 (Add)                    (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_270[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, 14, 14, 1024) 0           add_89[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_273[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_275[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_90 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_273[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, 14, 14, 1024) 0           add_90[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_276[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_91 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_276[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 14, 14, 1024) 0           add_91[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_279[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_280[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_281[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_92 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_279[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_282 (Activation)     (None, 14, 14, 1024) 0           add_92[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_283 (Activation)     (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_283[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_284 (Activation)     (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_284[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_93 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_285 (Activation)     (None, 14, 14, 1024) 0           add_93[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_286 (Activation)     (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_286[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_287 (Activation)     (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_287[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_94 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_288 (Activation)     (None, 7, 7, 2048)   0           add_94[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_288[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_289 (Activation)     (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_289[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_290 (Activation)     (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_290[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_95 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_288[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_291 (Activation)     (None, 7, 7, 2048)   0           add_95[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_292 (Activation)     (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_292[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_293 (Activation)     (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_293[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_96 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_294 (Activation)     (None, 7, 7, 2048)   0           add_96[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           activation_294[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 2048)         0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 512)          1049088     dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 128)          65664       dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 10)           1290        dense_16[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 24,703,754\n",
      "Trainable params: 1,116,042\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 以訓練好的 ResNet50 為基礎來建立模型，\n",
    "# 捨棄 ResNet50 頂層的 fully connected layers\n",
    "net = ResNet50(include_top=True, \n",
    "               weights='imagenet', \n",
    "               input_tensor=None,\n",
    "               input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
    "\n",
    "# remove classification layer\n",
    "net.layers.pop()\n",
    "net = Model(inputs=net.input, outputs=net.layers[-1].output)\n",
    "\n",
    "# 設定凍結與要進行訓練的網路層\n",
    "for layer in net.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = net.output\n",
    "#x = Flatten()(x)\n",
    "\n",
    "# 增加 DropOut layer\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "# 增加 Dense layer，以 softmax 產生個類別的機率值\n",
    "output_layer = Dense(NUM_CLASSES, activation='softmax', kernel_initializer='he_normal')(x)\n",
    "\n",
    "net_final = Model(inputs=net.input, outputs=output_layer)\n",
    "\n",
    "# 使用 Adam optimizer，以較低的 learning rate 進行 fine-tuning\n",
    "net_final.compile(optimizer=RMSprop(learning_rate=lr_schedule(0)),\n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# 輸出整個網路結構\n",
    "print(net_final.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mosv921yGDY9"
   },
   "outputs": [],
   "source": [
    "# Prepare model model saving directory.\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = f'cifar10_resnet50-final_{NUM_EPOCHS:03d}.h5'\n",
    "\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_accuracy',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=3,\n",
    "                               min_lr=0.5e-8)\n",
    "\n",
    "callbacks = [checkpoint, lr_reducer, lr_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "CWxNg-MEGDZA",
    "outputId": "e784d056-7532-402b-9760-b31ba2bfe834"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "Found 50000 images belonging to 10 classes.\n",
      "Found 10000 images belonging to 10 classes.\n",
      "Class #0 = [0]\n",
      "Class #1 = [1]\n",
      "Class #2 = [2]\n",
      "Class #3 = [3]\n",
      "Class #4 = [4]\n",
      "Class #5 = [5]\n",
      "Class #6 = [6]\n",
      "Class #7 = [7]\n",
      "Class #8 = [8]\n",
      "Class #9 = [9]\n",
      "Epoch 1/40\n",
      "Learning rate:  0.001\n",
      "781/781 [==============================] - 646s 827ms/step - loss: 1.0860 - accuracy: 0.6216 - val_loss: 0.2728 - val_accuracy: 0.6990\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.69902, saving model to /content/saved_models/cifar10_resnet50-final_040.h5\n",
      "Epoch 2/40\n",
      "Learning rate:  0.001\n",
      "781/781 [==============================] - 647s 829ms/step - loss: 0.8639 - accuracy: 0.7018 - val_loss: 0.2836 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.69902\n",
      "Epoch 3/40\n",
      "Learning rate:  0.001\n",
      "781/781 [==============================] - 640s 819ms/step - loss: 0.8228 - accuracy: 0.7166 - val_loss: 0.3963 - val_accuracy: 0.6770\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.69902\n",
      "Epoch 4/40\n",
      "Learning rate:  0.001\n",
      "781/781 [==============================] - 647s 828ms/step - loss: 0.7937 - accuracy: 0.7259 - val_loss: 0.0948 - val_accuracy: 0.7066\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.69902 to 0.70662, saving model to /content/saved_models/cifar10_resnet50-final_040.h5\n",
      "Epoch 5/40\n",
      "Learning rate:  0.001\n",
      "781/781 [==============================] - 645s 826ms/step - loss: 0.7751 - accuracy: 0.7357 - val_loss: 0.1098 - val_accuracy: 0.6486\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.70662\n",
      "Epoch 6/40\n",
      "Learning rate:  0.001\n",
      "781/781 [==============================] - 645s 826ms/step - loss: 0.7592 - accuracy: 0.7412 - val_loss: 0.4512 - val_accuracy: 0.6853\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.70662\n",
      "Epoch 7/40\n",
      "Learning rate:  0.001\n",
      "781/781 [==============================] - 648s 830ms/step - loss: 0.7467 - accuracy: 0.7472 - val_loss: 0.2044 - val_accuracy: 0.6540\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.70662\n",
      "Epoch 8/40\n",
      "Learning rate:  0.001\n",
      "781/781 [==============================] - 645s 825ms/step - loss: 0.7390 - accuracy: 0.7503 - val_loss: 0.3663 - val_accuracy: 0.6934\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.70662\n",
      "Epoch 9/40\n",
      "Learning rate:  0.001\n",
      "781/781 [==============================] - 633s 810ms/step - loss: 0.7285 - accuracy: 0.7545 - val_loss: 0.7280 - val_accuracy: 0.6769\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.70662\n",
      "Epoch 10/40\n",
      "Learning rate:  0.001\n",
      "781/781 [==============================] - 641s 821ms/step - loss: 0.7242 - accuracy: 0.7550 - val_loss: 0.3793 - val_accuracy: 0.7198\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.70662 to 0.71981, saving model to /content/saved_models/cifar10_resnet50-final_040.h5\n",
      "Epoch 11/40\n",
      "Learning rate:  0.001\n",
      "781/781 [==============================] - 639s 818ms/step - loss: 0.7225 - accuracy: 0.7565 - val_loss: 1.4484 - val_accuracy: 0.7027\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.71981\n",
      "Epoch 12/40\n",
      "Learning rate:  0.0003\n",
      "781/781 [==============================] - 632s 809ms/step - loss: 0.6484 - accuracy: 0.7776 - val_loss: 0.3615 - val_accuracy: 0.7072\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.71981\n",
      "Epoch 13/40\n",
      "Learning rate:  0.0003\n",
      "781/781 [==============================] - 628s 804ms/step - loss: 0.6456 - accuracy: 0.7803 - val_loss: 0.3959 - val_accuracy: 0.7155\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.71981\n",
      "Epoch 14/40\n",
      "Learning rate:  0.0003\n",
      "781/781 [==============================] - 632s 809ms/step - loss: 0.6327 - accuracy: 0.7847 - val_loss: 0.3418 - val_accuracy: 0.7114\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.71981\n",
      "Epoch 15/40\n",
      "Learning rate:  0.0003\n",
      "781/781 [==============================] - 636s 814ms/step - loss: 0.6352 - accuracy: 0.7846 - val_loss: 0.3724 - val_accuracy: 0.7204\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.71981 to 0.72041, saving model to /content/saved_models/cifar10_resnet50-final_040.h5\n",
      "Epoch 16/40\n",
      "Learning rate:  0.0003\n",
      "781/781 [==============================] - 636s 815ms/step - loss: 0.6314 - accuracy: 0.7880 - val_loss: 1.7221 - val_accuracy: 0.7169\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.72041\n",
      "Epoch 17/40\n",
      "Learning rate:  0.0003\n",
      "781/781 [==============================] - 638s 817ms/step - loss: 0.6242 - accuracy: 0.7890 - val_loss: 1.1730 - val_accuracy: 0.7208\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.72041 to 0.72081, saving model to /content/saved_models/cifar10_resnet50-final_040.h5\n",
      "Epoch 18/40\n",
      "Learning rate:  0.0003\n",
      "781/781 [==============================] - 630s 807ms/step - loss: 0.6257 - accuracy: 0.7919 - val_loss: 1.4803 - val_accuracy: 0.7027\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.72081\n",
      "Epoch 19/40\n",
      "Learning rate:  0.0003\n",
      "781/781 [==============================] - 638s 817ms/step - loss: 0.6183 - accuracy: 0.7927 - val_loss: 1.7413 - val_accuracy: 0.6982\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.72081\n",
      "Epoch 20/40\n",
      "Learning rate:  0.0003\n",
      "781/781 [==============================] - 635s 814ms/step - loss: 0.6187 - accuracy: 0.7905 - val_loss: 1.1197 - val_accuracy: 0.7145\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.72081\n",
      "Epoch 21/40\n",
      "Learning rate:  0.0003\n",
      "781/781 [==============================] - 636s 815ms/step - loss: 0.6188 - accuracy: 0.7913 - val_loss: 1.9741 - val_accuracy: 0.6988\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.72081\n",
      "Epoch 22/40\n",
      "Learning rate:  0.0001\n",
      "781/781 [==============================] - 648s 830ms/step - loss: 0.5947 - accuracy: 0.7984 - val_loss: 2.2561 - val_accuracy: 0.7084\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.72081\n",
      "Epoch 23/40\n",
      "Learning rate:  0.0001\n",
      "781/781 [==============================] - 643s 823ms/step - loss: 0.5966 - accuracy: 0.7976 - val_loss: 1.8917 - val_accuracy: 0.7131\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.72081\n",
      "Epoch 24/40\n",
      "Learning rate:  0.0001\n",
      "781/781 [==============================] - 652s 835ms/step - loss: 0.5930 - accuracy: 0.7983 - val_loss: 1.6764 - val_accuracy: 0.7099\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.72081\n",
      "Epoch 25/40\n",
      "Learning rate:  0.0001\n",
      "781/781 [==============================] - 648s 829ms/step - loss: 0.5939 - accuracy: 0.7992 - val_loss: 1.7015 - val_accuracy: 0.7055\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.72081\n",
      "Epoch 26/40\n",
      "Learning rate:  0.0001\n",
      "781/781 [==============================] - 649s 831ms/step - loss: 0.5906 - accuracy: 0.8007 - val_loss: 2.5081 - val_accuracy: 0.6965\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.72081\n",
      "Epoch 27/40\n",
      "Learning rate:  0.0001\n",
      "781/781 [==============================] - 650s 832ms/step - loss: 0.5845 - accuracy: 0.7999 - val_loss: 2.7376 - val_accuracy: 0.7038\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.72081\n",
      "Epoch 28/40\n",
      "Learning rate:  0.0001\n",
      "781/781 [==============================] - 647s 828ms/step - loss: 0.5897 - accuracy: 0.8037 - val_loss: 1.5321 - val_accuracy: 0.7152\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.72081\n",
      "Epoch 29/40\n",
      "Learning rate:  0.0001\n",
      "211/781 [=======>......................] - ETA: 7:15 - loss: 0.5789 - accuracy: 0.8055"
     ]
    }
   ],
   "source": [
    "# Run training, with or without data augmentation.\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    net_final.fit(x_train, y_train,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=NUM_EPOCHS,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    # 透過 data augmentation 產生訓練與驗證用的影像資料\n",
    "    train_datagen = ImageDataGenerator(rotation_range=30,\n",
    "                                       width_shift_range=0.2,\n",
    "                                       height_shift_range=0.2,\n",
    "                                       shear_range=0.1,\n",
    "                                       zoom_range=0.1,\n",
    "                                       channel_shift_range=10,\n",
    "                                       horizontal_flip=True,\n",
    "                                       fill_mode='nearest')\n",
    "    train_batches = train_datagen.flow_from_directory(DATASET_PATH + '/train_org',\n",
    "                                                      target_size=IMAGE_SIZE,\n",
    "                                                      interpolation='bicubic',\n",
    "                                                      class_mode='categorical',\n",
    "                                                      shuffle=True,\n",
    "                                                      batch_size=BATCH_SIZE)\n",
    "\n",
    "    valid_datagen = ImageDataGenerator()\n",
    "    valid_batches = valid_datagen.flow_from_directory(DATASET_PATH + '/valid_org',\n",
    "                                                      target_size=IMAGE_SIZE,\n",
    "                                                      interpolation='bicubic',\n",
    "                                                      class_mode='categorical',\n",
    "                                                      shuffle=False,\n",
    "                                                      batch_size=BATCH_SIZE)\n",
    "\n",
    "    # 輸出各類別的索引值\n",
    "    for cls, idx in train_batches.class_indices.items():\n",
    "        print('Class #{} = {}'.format(idx, cls))\n",
    "\n",
    "\n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    train_datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    # 訓練模型\n",
    "    net_final.fit_generator(train_batches,\n",
    "                            steps_per_epoch = train_batches.samples // BATCH_SIZE,\n",
    "                            validation_data = valid_batches,\n",
    "                            validation_steps = valid_batches.samples // BATCH_SIZE,\n",
    "                            epochs = NUM_EPOCHS, \n",
    "                            verbose=1,\n",
    "                            callbacks=callbacks)\n",
    "    \n",
    "#     net_final.fit_generator(datagen.flow(x_train, y_train, batch_size=BATCH_SIZE),\n",
    "#                         validation_data=(x_test, y_test),\n",
    "#                         epochs=NUM_EPOCHS, verbose=1,   \n",
    "#                         callbacks=callbacks)\n",
    "    \n",
    "# Score trained model.\n",
    "scores = net_final.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w7shxGeEGDZC"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "0 : airplain (飛機)\n",
    "1 : automobile (汽車)\n",
    "2 : bird (鳥)\n",
    "3 : cat (貓)\n",
    "4 : deer (鹿)\n",
    "5 : dog (狗)\n",
    "6 : frog (青蛙)\n",
    "7 : horse (馬)\n",
    "8 : ship (船)\n",
    "9 : truck (卡車)\n",
    "'''    \n",
    "def array_to_image(X, y, path=\"train\", resize=False, imgsize=(224,224)):\n",
    "    from PIL import Image\n",
    "    import numpy as np\n",
    "    import os\n",
    "    \n",
    "    path = os.path.join(os.getcwd(), DATASET_PATH, path)        \n",
    "    # 檢查路徑是否存在\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "        print(\"creat dir\", path)\n",
    "    \n",
    "    if len(X) != len(y):\n",
    "        print(\"data Mismatch\")\n",
    "        return\n",
    "\n",
    "    for i in range(0, len(X)):\n",
    "        filepath = os.path.join(path, str(y[i]))\n",
    "        if not os.path.exists(filepath):\n",
    "            os.mkdir(filepath)\n",
    "            print(\"creat dir\", filepath)\n",
    "            \n",
    "        # 將圖片使用 BICUBIC 方式延伸到 224 x 224\n",
    "        img = X[i]\n",
    "        img = Image.fromarray(img)\n",
    "        if resize:\n",
    "            img = img.resize(imgsize, Image.BICUBIC)\n",
    "        filename = os.path.join(filepath, str(i)+\".png\")\n",
    "        img.save(filename)\n",
    "        #print(\"save\", filename)\n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MdpMPG9ZGDZE"
   },
   "outputs": [],
   "source": [
    "#array_to_image(x_train, y_train, \"train\", True, IMAGE_SIZE)\n",
    "array_to_image(x_train, y_train, \"train_org\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_5F3wzYDGDZG"
   },
   "outputs": [],
   "source": [
    "#array_to_image(x_test, y_test, \"valid\", True, IMAGE_SIZE)\n",
    "array_to_image(x_test, y_test, \"valid_org\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pXf8Sw1YMUXE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Copy of Day_100_transfer_learning_HW.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
